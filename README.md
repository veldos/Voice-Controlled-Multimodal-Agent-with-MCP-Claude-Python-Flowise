# ğŸ”§ Voice-Controlled Multimodal Agent with MCP, Claude, Python & Flowise

## ğŸ§  Project Overview

This project demonstrates how to build a secure, modular **multimodal AI agent** using the **Model Context Protocol (MCP)**, capable of:

* Accepting **voice input** ğŸ—£ï¸
* Executing **structured tool calls** ğŸ› ï¸
* Retrieving **image, text, and document resources** ğŸ“¸
* Performing **RAG (retrieval-augmented generation)** using **Pinecone** ğŸ“ˆ
* Delivering results through **Claude Desktop** or **Cursor** ğŸ–¥ï¸

## ğŸ§± Tech Stack

* **Claude Desktop** or **Cursor** (MCP clients)
* **Python** + `modelcontextprotocol` SDK (MCP servers)
* **n8n** for automation triggers
* **Flowise** for tool chaining and vector-based search
* **Pinecone** + SQLite for retrieval
* **OpenAI Whisper** or browser-based voice input

## ğŸ’¡ Key Capabilities

| Capability | How It's Implemented |
|------------|---------------------|
| **MCP Tool Server** | Built in Python, exposes commands via JSON schema |
| **Multimodal input** | Voice input transcribed and routed via MCP |
| **RAG pipeline** | Search + summarize using Flowise + Pinecone |
| **Security & Privacy** | API key access, SSE monitoring, GDPR-safe logging |
| **Prompt Engineering** | Custom templates defined in Python for Claude/GPT use |
| **Real-time interactivity** | Streamable HTTP + SSE endpoints |
| **Multi-client compatibility** | Tested with Cursor, Claude Desktop, and n8n UI |

## ğŸ—‚ï¸ Project Structure

```
Project/
â”œâ”€â”€ mcp_servers/
â”‚   â”œâ”€â”€ voice_agent_server.py      # Main MCP server
â”‚   â”œâ”€â”€ multimodal_tools.py        # Image/document processing
â”‚   â”œâ”€â”€ rag_server.py              # RAG implementation
â”‚   â””â”€â”€ security_server.py         # Security & logging
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ claude_desktop_config.json # Claude Desktop MCP config
â”‚   â”œâ”€â”€ cursor_config.json         # Cursor MCP config
â”‚   â”œâ”€â”€ n8n_workflows.json         # n8n automation workflows
â”‚   â””â”€â”€ flowise_config.json        # Flowise tool chains
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ prompt_templates.py        # Custom prompt templates
â”‚   â””â”€â”€ response_templates.py      # Response formatting
â”œâ”€â”€ schemas/
â”‚   â”œâ”€â”€ tool_schemas.json          # JSON schemas for tools
â”‚   â””â”€â”€ api_schemas.json           # API endpoint schemas
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture.md            # System architecture
â”‚   â”œâ”€â”€ setup_guide.md            # Setup instructions
â”‚   â””â”€â”€ demo_script.md            # Demo scenarios
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ .env.example                  # Environment variables template
â””â”€â”€ demo_video_script.md          # Demo video script
```

## ğŸš€ Quick Start

1. **Install Dependencies**
   ```bash
   pip install -r requirements.txt
   ```

2. **Set up Environment Variables**
   ```bash
   cp .env.example .env
   # Edit .env with your API keys
   ```

3. **Start MCP Servers**
   ```bash
   python mcp_servers/voice_agent_server.py
   ```

4. **Configure Claude Desktop/Cursor**
   - Copy `config/claude_desktop_config.json` to your Claude Desktop config
   - Or copy `config/cursor_config.json` to your Cursor config

5. **Test Voice Input**
   - Open Claude Desktop or Cursor
   - Use voice commands like "Search for information about AI"
   - Watch the multimodal agent process your request!

## ğŸ¯ Demo Scenarios

1. **Voice-to-RAG**: "Tell me about machine learning trends"
2. **Image Analysis**: "Analyze this screenshot and explain what's happening"
3. **Document Processing**: "Summarize this PDF and extract key points"
4. **Web Search + Synthesis**: "Research competitors and create a comparison"

## ğŸ” Security Features

* API key validation and rotation
* Request filtering and sanitization
* GDPR-compliant logging
* Rate limiting and abuse detection
* Secure credential management

## ğŸ“Š Monitoring & Analytics

* Real-time request tracking via SSE
* Performance metrics and latency monitoring
* Error logging and debugging tools
* Usage analytics and reporting

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

* Anthropic for Claude and MCP
* OpenAI for Whisper and GPT models
* Pinecone for vector search
* The open-source community for amazing tools

---

**Built with â¤ï¸ for the future of multimodal AI**
